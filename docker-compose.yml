version: '3.8'

services:
  tgi:
    image: ghcr.io/huggingface/text-generation-inference:latest
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - MODEL_ID=mistralai/Mistral-7B-Instruct-v0.2-fr
    command: ["--model-id", "mistralai/Mistral-7B-Instruct-v0.2-fr", "--max-input-length", "2048", "--max-total-tokens", "4096"]
    volumes:
      - ./models:/data
    ports:
      - "8081:80"  # TGI API and OpenAI endpoint
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    networks:
      - tgi-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s

  openwebui:
    image: ghcr.io/open-webui/open-webui:main
    environment:
      - OPENAI_API_BASE=http://tgi:80/v1
      - OPENAI_API_KEY=not-needed
      - ENDPOINTS=http://tgi:80/v1
      - DEFAULT_ENDPOINT=http://tgi:80/v1
    ports:
      - "8080:8080"  # OpenWebUI interface
    depends_on:
      - tgi
    restart: unless-stopped
    networks:
      - tgi-network

networks:
  tgi-network:
    driver: bridge

volumes:
  models: